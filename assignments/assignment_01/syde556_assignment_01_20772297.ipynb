{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 556/750 --- Assignment 1\n",
    "**Student ID: 00000000**\n",
    "\n",
    "*Note:* Please include your numerical student ID only, do *not* include your name.\n",
    "\n",
    "*Note:* Refer to the [PDF](https://github.com/celiasmith/syde556-f22/raw/master/assignments/assignment_01/syde556_assignment_01.pdf) for the full instructions (including some hints), this notebook contains abbreviated instructions only. Cells you need to fill out are marked with a \"writing hand\" symbol. Of course, you can add new cells in between the instructions, but please leave the instructions intact to facilitate marking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib -- you shouldn't need any other libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize # For question 2.1b)\n",
    "\n",
    "# Fix the numpy random seed for reproducible results\n",
    "np.random.seed(18945)\n",
    "\n",
    "# Some formating options\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Representation of Scalars\n",
    "\n",
    "## 1.1 Basic encoding and decoding\n",
    "\n",
    "**a) Computing gain and bias.** In general, for a neuron model $a = G[J]$ (and assuming that the inverse $J = G^{-1}[a]$ exists), solve the following system of equations to compute the gain $\\alpha$, and the bias $J^\\mathrm{bias}$ given a maximum rate $a^\\mathrm{max}$ and an $x$-intercept $\\xi$.\n",
    "\n",
    "$$a^\\mathrm{max} = G[\\alpha + J^\\mathrm{bias}] \\,, \\quad\\quad 0 = G[\\alpha \\xi + J^\\mathrm{bias}] \\,.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(J):\n",
    "    return np.maximum(0, J)\n",
    "\n",
    "a_max = np.random.uniform(100, 200)\n",
    "upsilon = np.random.uniform(-0.95, 0.95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simplify these equations for the specific case $G[J] = \\max(J, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542.2046566430131, -426.8612703864534)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = a_max / (1- upsilon)\n",
    "J_bias = a_max * upsilon / (upsilon - 1)\n",
    "alpha,J_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Neuron tuning curves.** Plot the neuron tuning curves $a_i(x)$ for 16 randomly generated neurons following the intercept and maximum rate distributions described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"397.6075pt\" height=\"297.190125pt\" viewBox=\"0 0 397.6075 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-09-25T17:51:27.630833</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 297.190125 \nL 397.6075 297.190125 \nL 397.6075 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \nL 390.4075 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m36335627b4\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"49.520227\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −1.00 -->\n      <g transform=\"translate(34.197571 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"90.102045\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −0.75 -->\n      <g transform=\"translate(74.779389 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"130.683864\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −0.50 -->\n      <g transform=\"translate(115.361207 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"171.265682\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −0.25 -->\n      <g transform=\"translate(155.943026 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"211.8475\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.00 -->\n      <g transform=\"translate(200.714688 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"252.429318\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.25 -->\n      <g transform=\"translate(241.296506 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"293.011136\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.50 -->\n      <g transform=\"translate(281.878324 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"333.592955\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.75 -->\n      <g transform=\"translate(322.460142 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m36335627b4\" x=\"374.174773\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.00 -->\n      <g transform=\"translate(363.04196 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m59e3fd0fcb\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"261.216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 265.015219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"224.840459\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 25 -->\n      <g transform=\"translate(13.5625 228.639677)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"188.464917\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 192.264136)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"152.089376\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 75 -->\n      <g transform=\"translate(13.5625 155.888595)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"115.713834\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 119.513053)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"79.338293\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 83.137512)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m59e3fd0fcb\" x=\"33.2875\" y=\"42.962752\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 46.76197)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.520227 261.216 \nL 57.844703 261.216 \nL 66.169178 261.216 \nL 74.493654 261.216 \nL 82.818129 261.216 \nL 91.142605 261.216 \nL 99.46708 261.216 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 257.759385 \nL 191.036311 247.790491 \nL 199.360787 237.821598 \nL 207.685262 227.852704 \nL 216.009738 217.88381 \nL 224.334213 207.914917 \nL 232.658689 197.946023 \nL 240.983164 187.97713 \nL 249.30764 178.008236 \nL 257.632115 168.039343 \nL 265.956591 158.070449 \nL 274.281066 148.101556 \nL 282.605542 138.132662 \nL 290.930017 128.163769 \nL 299.254493 118.194875 \nL 307.578969 108.225982 \nL 315.903444 98.257088 \nL 324.22792 88.288195 \nL 332.552395 78.319301 \nL 340.876871 68.350408 \nL 349.201346 58.381514 \nL 357.525822 48.412621 \nL 365.850297 38.443727 \nL 374.174773 28.474834 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.520227 108.214447 \nL 57.844703 186.115909 \nL 66.169178 261.216 \nL 74.493654 261.216 \nL 82.818129 261.216 \nL 91.142605 261.216 \nL 99.46708 261.216 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 261.216 \nL 324.22792 261.216 \nL 332.552395 261.216 \nL 340.876871 261.216 \nL 349.201346 261.216 \nL 357.525822 261.216 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.520227 31.940305 \nL 57.844703 67.496808 \nL 66.169178 103.053311 \nL 74.493654 138.609815 \nL 82.818129 174.166318 \nL 91.142605 209.722821 \nL 99.46708 245.279324 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 261.216 \nL 324.22792 261.216 \nL 332.552395 261.216 \nL 340.876871 261.216 \nL 349.201346 261.216 \nL 357.525822 261.216 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.520227 261.216 \nL 57.844703 261.216 \nL 66.169178 261.216 \nL 74.493654 261.216 \nL 82.818129 261.216 \nL 91.142605 261.216 \nL 99.46708 261.216 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 254.560318 \nL 257.632115 242.205119 \nL 265.956591 229.84992 \nL 274.281066 217.49472 \nL 282.605542 205.139521 \nL 290.930017 192.784322 \nL 299.254493 180.429122 \nL 307.578969 168.073923 \nL 315.903444 155.718724 \nL 324.22792 143.363524 \nL 332.552395 131.008325 \nL 340.876871 118.653126 \nL 349.201346 106.297926 \nL 357.525822 93.942727 \nL 365.850297 81.587528 \nL 374.174773 69.232328 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.520227 91.35171 \nL 57.844703 104.095119 \nL 66.169178 116.838528 \nL 74.493654 129.581937 \nL 82.818129 142.325346 \nL 91.142605 155.068755 \nL 99.46708 167.812164 \nL 107.791556 180.555573 \nL 116.116031 193.298982 \nL 124.440507 206.042391 \nL 132.764983 218.7858 \nL 141.089458 231.529209 \nL 149.413934 244.272618 \nL 157.738409 257.016027 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 261.216 \nL 324.22792 261.216 \nL 332.552395 261.216 \nL 340.876871 261.216 \nL 349.201346 261.216 \nL 357.525822 261.216 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.520227 39.608336 \nL 57.844703 54.530515 \nL 66.169178 69.452695 \nL 74.493654 84.374874 \nL 82.818129 99.297054 \nL 91.142605 114.219233 \nL 99.46708 129.141412 \nL 107.791556 144.063592 \nL 116.116031 158.985771 \nL 124.440507 173.90795 \nL 132.764983 188.83013 \nL 141.089458 203.752309 \nL 149.413934 218.674488 \nL 157.738409 233.596668 \nL 166.062885 248.518847 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 261.216 \nL 324.22792 261.216 \nL 332.552395 261.216 \nL 340.876871 261.216 \nL 349.201346 261.216 \nL 357.525822 261.216 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.520227 23.950713 \nL 57.844703 32.490547 \nL 66.169178 41.030381 \nL 74.493654 49.570215 \nL 82.818129 58.110049 \nL 91.142605 66.649883 \nL 99.46708 75.189718 \nL 107.791556 83.729552 \nL 116.116031 92.269386 \nL 124.440507 100.80922 \nL 132.764983 109.349054 \nL 141.089458 117.888888 \nL 149.413934 126.428722 \nL 157.738409 134.968557 \nL 166.062885 143.508391 \nL 174.38736 152.048225 \nL 182.711836 160.588059 \nL 191.036311 169.127893 \nL 199.360787 177.667727 \nL 207.685262 186.207561 \nL 216.009738 194.747396 \nL 224.334213 203.28723 \nL 232.658689 211.827064 \nL 240.983164 220.366898 \nL 249.30764 228.906732 \nL 257.632115 237.446566 \nL 265.956591 245.9864 \nL 274.281066 254.526235 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 261.216 \nL 324.22792 261.216 \nL 332.552395 261.216 \nL 340.876871 261.216 \nL 349.201346 261.216 \nL 357.525822 261.216 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #e377c2; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.520227 97.313591 \nL 57.844703 101.686813 \nL 66.169178 106.060036 \nL 74.493654 110.433258 \nL 82.818129 114.806481 \nL 91.142605 119.179703 \nL 99.46708 123.552926 \nL 107.791556 127.926148 \nL 116.116031 132.29937 \nL 124.440507 136.672593 \nL 132.764983 141.045815 \nL 141.089458 145.419038 \nL 149.413934 149.79226 \nL 157.738409 154.165483 \nL 166.062885 158.538705 \nL 174.38736 162.911927 \nL 182.711836 167.28515 \nL 191.036311 171.658372 \nL 199.360787 176.031595 \nL 207.685262 180.404817 \nL 216.009738 184.77804 \nL 224.334213 189.151262 \nL 232.658689 193.524484 \nL 240.983164 197.897707 \nL 249.30764 202.270929 \nL 257.632115 206.644152 \nL 265.956591 211.017374 \nL 274.281066 215.390597 \nL 282.605542 219.763819 \nL 290.930017 224.137041 \nL 299.254493 228.510264 \nL 307.578969 232.883486 \nL 315.903444 237.256709 \nL 324.22792 241.629931 \nL 332.552395 246.003154 \nL 340.876871 250.376376 \nL 349.201346 254.749598 \nL 357.525822 259.122821 \nL 365.850297 261.216 \nL 374.174773 261.216 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 49.520227 261.216 \nL 57.844703 261.216 \nL 66.169178 261.216 \nL 74.493654 261.216 \nL 82.818129 261.216 \nL 91.142605 261.216 \nL 99.46708 261.216 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 257.749725 \nL 290.930017 236.072113 \nL 299.254493 214.394502 \nL 307.578969 192.716891 \nL 315.903444 171.039279 \nL 324.22792 149.361668 \nL 332.552395 127.684057 \nL 340.876871 106.006445 \nL 349.201346 84.328834 \nL 357.525822 62.651223 \nL 365.850297 40.973611 \nL 374.174773 19.296 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #bcbd22; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.520227 261.216 \nL 57.844703 261.216 \nL 66.169178 261.216 \nL 74.493654 261.216 \nL 82.818129 261.216 \nL 91.142605 261.216 \nL 99.46708 261.216 \nL 107.791556 261.216 \nL 116.116031 261.216 \nL 124.440507 261.216 \nL 132.764983 261.216 \nL 141.089458 261.216 \nL 149.413934 261.216 \nL 157.738409 261.216 \nL 166.062885 261.216 \nL 174.38736 261.216 \nL 182.711836 261.216 \nL 191.036311 261.216 \nL 199.360787 261.216 \nL 207.685262 261.216 \nL 216.009738 261.216 \nL 224.334213 261.216 \nL 232.658689 261.216 \nL 240.983164 261.216 \nL 249.30764 261.216 \nL 257.632115 261.216 \nL 265.956591 261.216 \nL 274.281066 261.216 \nL 282.605542 261.216 \nL 290.930017 261.216 \nL 299.254493 261.216 \nL 307.578969 261.216 \nL 315.903444 257.356388 \nL 324.22792 233.437572 \nL 332.552395 209.518756 \nL 340.876871 185.59994 \nL 349.201346 161.681124 \nL 357.525822 137.762308 \nL 365.850297 113.843492 \nL 374.174773 89.924676 \n\" clip-path=\"url(#p6cda15f850)\" style=\"fill: none; stroke: #17becf; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 273.312 \nL 33.2875 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 390.4075 273.312 \nL 390.4075 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 390.4075 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6cda15f850\">\n   <rect x=\"33.2875\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_neurons(num_neurons):\n",
    "    for i in range(num_neurons):\n",
    "        x = np.linspace(-1, 1, 40)\n",
    "        a_max = np.random.uniform(100, 200)\n",
    "        upsilon = np.random.uniform(-0.95, 0.95)\n",
    "        e = np.random.choice([-1, 1])\n",
    "        alpha = a_max / (1- upsilon)\n",
    "        J_bias = a_max * upsilon / (upsilon - 1)\n",
    "        a_x = G(alpha *np.dot(x,e) + J_bias)\n",
    "        plt.plot(x, a_x)\n",
    "    plt.show()\n",
    "plot_neurons(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Computing identity decoders.** Compute the optimal identity decoder $\\vec d$ for those 16 neurons (as shown in class). Report the value of the individual decoder coefficients. Compute $d$ using the matrix notation mentioned in the course notes. Do not apply any regularization. $A$ is the matrix of activities (the same data used to generate the plot in 1.1b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = np.array(...) # n x N array\n",
    "X = np.array(...) # d x N array\n",
    "D = np.linalg.lstsq(\n",
    "A @ A.T + 0.5 * N * np.square(sigma) * np.eye(n), A @ X.T,\n",
    "rcond=None)[0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Evaluating decoding errors.** Compute and plot $\\hat{x}=\\sum_i d_i a_i(x)$. Overlay on the plot the line $y=x$. Make a separate plot of $x-\\hat{x}$ to see what the error looks like. Report the Root Mean Squared Error (RMSE) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Decoding under noise.** Now try decoding under noise. Add random normally distributed noise to $a$ and decode again. The noise is a random variable with mean $\\mu=0$ and standard deviation of $\\sigma=0.2 \\max(A)$ (where $\\max(A)$ is the maximum firing rate of all the neurons). Resample this variable for every different $x$ value for every different neuron. Create all the same plots as in part d). Report the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Accounting for decoder noise.** Recompute the decoder $\\vec d$ taking noise into account (i.e., apply the appropriate regularization, as shown in class). Show how these decoders behave when decoding both with and without noise added to $a$ by making the same plots as in d) and e). Report the RMSE for all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Interpretation.** Show a 2x2 table of the four RMSE values reported in parts d), e), and f). This should show the effects of adding noise and whether the decoders $d$ are computed taking noise into account. Write a few sentences commenting on what the table shows, i.e., what the effect of adding noise to the activities is with respect to the measured error and why accounting for noise when computing the decoders increases/decreases/does not change the measured RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploring sources of error\n",
    "\n",
    "**a) Exploring error due to distortion and noise.** Plot the error due to distortion $E_\\mathrm{dist}$ and the error due to noise $E_\\mathrm{noise}$ as a function of $n$, the number of neurons. Generate two different loglog plots (one for each type of error) with $n$ values of at least $[4, 8, 16, 32, 64, 128, 256, 512]$. For each $n$ value, do at least $5$ runs and average the results. For each run, different $\\alpha$, $J^\\mathrm{bias}$, and $e$ values should be generated for each neuron. Compute $d$ taking noise into account, with $\\sigma = 0.1 \\max(A)$. Show visually that the errors are proportional to $1/n$ or $1/n^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Adapting the noise level.** Repeat part a) with $\\sigma = 0.01 \\max(A)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Interpretation.** What does the difference between the graphs in a) and b) tell us about the sources of error in neural populations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Leaky Integrate-and-Fire neurons\n",
    "\n",
    "**a) Computing gain and bias.** As in the second part of 1.1a), given a maximum firing rate $a^\\mathrm{max}$ and a bias $J^\\mathrm{bias}$, write down the equations for computing $\\alpha$ and the $J^\\mathrm{bias}$ for this specific neuron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Neuron tuning curves.** Generate the same plot as in 1.1b). Use $\\tau_\\mathrm{ref}=2 \\mathrm{ms}$ and $\\tau_{RC}=20 \\mathrm{ms}$. Use the same distribution of $x$-intercepts and maximum firing rates as in 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Impact of noise.** Generate the same four plots as in 1.1f) (adding/not adding noise to $A$, accounting/not accounting for noise when computing $\\vec d$), and report the RMSE both with and without noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reperesentation of Vectors\n",
    "\n",
    "## 2.1 Vector tuning curves\n",
    "\n",
    "**a) Plotting 2D tuning curves.** Plot the tuning curve of an LIF neuron whose 2D preferred direction vector is at an angle of $\\theta=-\\pi/4$, has an $x$-intercept at the origin $(0,0)$, and has a maximum firing rate of $100 \\mathrm{Hz}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Plotting the 2D tuning curve along the unit circle.** Plot the tuning curve for the same neuron as in a), but only considering the points around the unit circle, i.e., sample the activation for different angles $\\theta$. Fit a curve of the form $c_1 \\cos(c_2\\theta+c_3)+c_4$ to the tuning curve and plot it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** What makes a cosine a good choice for the curve fit in 2.1b? Why does it differ from the ideal curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Vector representation\n",
    "\n",
    "**a) Choosing encoding vectors.** Generate a set of $100$ random unit vectors uniformly distributed around the unit circle. These will be the encoders $\\vec e$ for $100$ neurons. Plot these vectors with a quiver or line plot (i.e., not just points, but lines/arrows to the points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Computing the identity decoder.** Use LIF neurons with the same properties as in question 1.3. When computing the decoders, take into account noise with $\\sigma = 0.2\\max(A)$. Plot the decoders in the same way you plotted the encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** How do these decoding vectors compare to the encoding vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Testing the decoder.** Generate 20 random $\\vec x$ values throughout the unit circle (i.e.,~with different directions and radiuses). For each $\\vec x$ value, determine the neural activity $a_i$ for each of the 100 neurons. Now decode these values (i.e. compute $\\hat{x} = D \\vec a$) using the decoders from part b). Plot the original and decoded values on the same graph in different colours, and compute the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Using encoders as decoders.** Repeat part d) but use the *encoders* as decoders. This is what Georgopoulos used in his original approach to decoding information from populations of neurons. Plot the decoded values and compute the RMSE. In addition, recompute the RMSE in both cases, but ignore the magnitude of the decoded vectors by normalizing before computing the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Discussion.** When computing the RMSE on the normalized vectors, using the encoders as decoders should result in a larger, yet still surprisingly small error. Thinking about random unit vectors in high dimensional spaces, why is this the case? What are the relative merits of these two approaches to decoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('syde556')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea648381ebf879092e303167a249236f5128567745923f8ad1822bc3f43881a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
